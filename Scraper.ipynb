{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome('C:/Windows/chromedriver_win32/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['username', 'date', 'comments'])\n",
    "for j in range(250):\n",
    "  driver.get('https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/p'+str(j+1))\n",
    "  for i in range(20):\n",
    "    df.loc[i+j*20, 'username'] = driver.find_elements_by_xpath('/html/body/div[1]/main/div/div[3]/div[5]/div[1]/ul/li['+ str(i+1) +']/div/div[2]/div[1]/span[1]/a[2]')[0].text\n",
    "    df.loc[i+j*20, 'date'] = driver.find_elements_by_xpath('/html/body/div[1]/main/div/div[3]/div[5]/div[1]/ul/li['+ str(i+1) +']/div/div[2]/div[2]/span/a/time')[0].text\n",
    "    df.loc[i+j*20, 'comments'] = driver.find_elements_by_xpath('/html/body/div[1]/main/div/div[3]/div[5]/div[1]/ul/li['+ str(i+1) +']/div/div[3]/div/div[1]')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to csv file\n",
    "import copy\n",
    "comments_clean = copy.deepcopy(df)\n",
    "comments_clean['comments'] = comments_clean['comments'].apply(lambda x :x.replace(\"\\n\",\" \"))\n",
    "comments_clean.to_csv('comments.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation and convert to lower case\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "comments_clean = pd.read_csv(\"comments.csv\")\n",
    "comments_clean['comments']=comments_clean['comments'].astype(str)\n",
    "comments_clean = comments_clean.dropna()\n",
    "comments_clean = comments_clean.drop(columns = 'Unnamed: 0')\n",
    "comments_clean = comments_clean.reset_index().drop(columns='index')\n",
    "comments_clean['comments'] = comments_clean['comments'].apply(lambda x :x.translate(str.maketrans('', '', string.punctuation)))\n",
    "comments_clean['comments'] = comments_clean['comments'].apply(lambda x :x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import models to brand conversion file \n",
    "models = pd.read_csv(\"models.csv\", header = None, names = ['brand','model'], encoding='windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace models by brands\n",
    "def model_to_brand(s):\n",
    "    for i in models.index.values:\n",
    "        s = s.replace(models[\"model\"][i].lower(),models[\"brand\"][i].lower())\n",
    "    return s\n",
    "comments_clean['comments_model_replace'] = comments_clean['comments'].apply(model_to_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize and remove stop words\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "comments_clean['comments_model_replace'] = comments_clean['comments_model_replace'].apply(word_tokenize).apply(set).apply(list)\n",
    "\n",
    "def remove_stopwords(s):\n",
    "    return [w for w in s if not w in stop_words] \n",
    "    \n",
    "comments_clean['comments_model_replace'] =  comments_clean['comments_model_replace'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a combined list of all words\n",
    "all_words = []\n",
    "for i in range(len(comments_clean)):\n",
    "    all_words+=comments_clean['comments_model_replace'][i]\n",
    "from nltk import FreqDist\n",
    "word_freq = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of all brand names\n",
    "model_names = models['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering counts for brands\n",
    "brand_counts = []\n",
    "for key,item in word_freq.most_common(1000):\n",
    "    if key in model_names:\n",
    "        temp = (key,item)\n",
    "        brand_counts.append(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bmw', 1401),\n",
       " ('acura', 529),\n",
       " ('audi', 439),\n",
       " ('infiniti', 415),\n",
       " ('honda', 403),\n",
       " ('toyata', 209),\n",
       " ('nissan', 191),\n",
       " ('volvo', 174),\n",
       " ('ford', 143),\n",
       " ('mercedes', 143)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 brands\n",
    "brand_counts[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
